# Experimentos Aprendizado por Reforço

## Descrição do Projeto
Este repositório contém scripts para experimentos de Aprendizado por Reforço utilizando os ambientes `Cliff Walking`, `Taxi`,`BlackJack` e `Frozen Lake` do Gymnasium. Os algoritmos empregados são os métodos de diferenças temporais Q-Learning e SARSA. O objetivo principal é identificar a influência dos hiperparâmetros no desempenho de cada um dos métodos.

## Estrutura do Repositório
- `Projeto_Aprendizado_por_Reforço_(BlackJack_e_FrozenLake)_Douglas_Felipe.ipynb`: Notebook com experimentos de Aprendizado por Reforço nos ambientes BlackJack e Frozen Lake.
- `Projeto_Aprendizado_por_Reforço_(Cliff_Walking_e_Taxi)_Douglas_Felipe.ipynb`: Notebook com experimentos de Aprendizado por Reforço nos ambientes Cliff Walking e Taxi.
- `Relatório - Douglas Felipe.docx`: Relatório detalhado dos experimentos em formato Word.
- `Relatório - Douglas Felipe.pdf`: Relatório detalhado dos experimentos em formato PDF.

## Objetivo
O objetivo dos experimentos é avaliar como diferentes combinações de hiperparâmetros influenciam o desempenho dos algoritmos Q-Learning e SARSA nos ambientes `Cliff Walking`, `Taxi`, `BlackJack` e `Frozen Lake`.

## Executando os Scripts no Google Colab
Os scripts foram projetados para serem executados no Google Colab, onde todas as dependências necessárias são instaladas automaticamente. Basta abrir o notebook correspondente no Google Colab e executar as células.

### Cliff Walking e Taxi
**Notebook:** `Projeto_Aprendizado_por_Reforço_(Cliff_Walking_e_Taxi)_Douglas_Felipe.ipynb`

**Execução:**
1. Abra o notebook no Google Colab.
2. Execute todas as células para treinar os agentes e visualizar os resultados.

### BlackJack e Frozen Lake
**Notebook:** `Projeto_Aprendizado_por_Reforço_(BlackJack_e_FrozenLake)_Douglas_Felipe.ipynb`

**Execução:**
1. Abra o notebook no Google Colab.
2. Execute todas as células para treinar os agentes e visualizar os resultados.
